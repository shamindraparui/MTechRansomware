{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_run_result=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import numpy \n",
    "import pandas\n",
    "#import sys\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "\n",
    "########################################################################################\n",
    "#             This script is used for selection of features in a random way.\n",
    "#             The first 32 features are of APIs, next 4 are of Assembly and\n",
    "#             the last 3 are of some properties of PE and its associated label\n",
    "#             and will train Random Forest\n",
    "#             date : 2-7-2020\n",
    "#             version : 2-7-v2\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "# following function randomly selects APIs or Assembly instruction depending on the call\n",
    "def select_randomly(number_of_selection,my_list):\n",
    "    global selected_features\n",
    "    list_length=len(my_list)-1\n",
    "    i=0\n",
    "    while i<number_of_selection:\n",
    "        n=random.randint(0,list_length)\n",
    "        selected_features.append(my_list[n])\n",
    "        i+=1\n",
    "    return None\n",
    "########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################ MAIN_START ########################################################\n",
    "\n",
    "\n",
    "# Following parameters are used for system configuration\n",
    "how_many_api=20\n",
    "how_many_asm=10\n",
    "scale_value=500*1048576\n",
    "size_of_test_data=0.20\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  Reading the lists named \"FrequentlyUsedAPI.list\", \"FrequentlyUsedASM.list\", \"EndFeature.list\" which\n",
    "#  was written by \"RandomFeatureSelection.py\" & \"FetchData.py\"\n",
    "\n",
    "with open(\"C:/Users/Gamer/Documents/Implementation/UpdatedFeature/FrequentlyUsedAPI.list\",\"rb\") as read_file:\n",
    "    frequently_used_api=pickle.load(read_file)\n",
    "    read_file.close()\n",
    "with open(\"C:/Users/Gamer/Documents/Implementation/UpdatedFeature/FrequentlyUsedASM.list\",\"rb\") as read_file:\n",
    "    frequently_used_asm=pickle.load(read_file)\n",
    "    read_file.close()\n",
    "with open(\"C:/Users/Gamer/Documents/Implementation/UpdatedFeature/EndFeature.list\",\"rb\") as read_file:\n",
    "    end_feature=pickle.load(read_file)\n",
    "    read_file.close()\n",
    "    \n",
    "\n",
    "# following list will store the features (randomly select total of 32 APIs & 4 assembly instructions)\n",
    "selected_features=[]\n",
    "\n",
    "\n",
    "# following function will randomly select features\n",
    "select_randomly(how_many_api,frequently_used_api[:40])\n",
    "select_randomly(how_many_api,frequently_used_api[100:140])\n",
    "\n",
    "temp=deepcopy(list(OrderedDict.fromkeys(selected_features)))\n",
    "selected_features.clear()\n",
    "selected_features=deepcopy(temp)\n",
    "temp.clear()\n",
    "asm_start_index=len(selected_features)\n",
    "\n",
    "select_randomly(how_many_asm,frequently_used_asm[:12])\n",
    "select_randomly(how_many_asm,frequently_used_asm[20:32])\n",
    "temp=deepcopy(list(OrderedDict.fromkeys(selected_features)))\n",
    "selected_features.clear()\n",
    "selected_features=deepcopy(temp)\n",
    "temp.clear()\n",
    "asm_end_index=asm_start_index + (len(selected_features[asm_start_index:]))\n",
    "selected_features+=end_feature\n",
    "#print(selected_features)\n",
    "\n",
    "\n",
    "# Loading the dataset into memory\n",
    "with open(\"C:/Users/Gamer/Documents/Implementation/UpdatedFeature/ALLdataset\",\"rb\") as my_dataset_read:\n",
    "    data_set=pickle.load(my_dataset_read)\n",
    "    my_dataset_read.close()\n",
    "\n",
    "data=data_set[selected_features]\n",
    "data=data.loc[:,~data.columns.duplicated()]\n",
    "\n",
    "print(\"Features are :\")\n",
    "print(selected_features)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# Scaling the frequency of each instruction\n",
    "row=len(data[\"size\"])\n",
    "i=0\n",
    "j=asm_start_index\n",
    "column=asm_end_index\n",
    "#sys.exit()\n",
    "while j <column:\n",
    "    i=0\n",
    "    while i< row:\n",
    "        scaled=0\n",
    "        has=data.iloc[i,j]\n",
    "        size=data.loc[i,\"size\"]\n",
    "        scaled=int((has/size)*scale_value)\n",
    "        #data.iat[i,j]=deepcopy(scaled)\n",
    "        data.iat[i,j]=deepcopy(scaled)\n",
    "        #print(scaled)\n",
    "        i+=1\n",
    "    j+=1\n",
    "with open(\"current_dataset.df\",\"wb\") as dfWrite:\n",
    "    pickle.dump(data,dfWrite)\n",
    "    dfWrite.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "import lightgbm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "\n",
    "# list to save the result\n",
    "final_result=[]\n",
    "final_result.append([\"Name\",\"F1\",\"Precision\",\"Recall\",\"TP\",\"TN\",\"FP\",\"FN\",\"FNR\"])\n",
    "#print(\"Name \\t Accuracy \\t F1 \\t TPR \\t FNR\\n\")\n",
    "#################################  NB  below  #################################################\n",
    "X=None\n",
    "Y=None\n",
    "X_train=None\n",
    "X_test=None\n",
    "Y_train=None\n",
    "Y_test=None\n",
    "\n",
    "X=data.drop([\"label\",\"size\",\"Entropy\",\"Name\",\"SectionCharacteristics\"], axis=1)\n",
    "Y=pandas.DataFrame(data[\"label\"])\n",
    "\n",
    "\n",
    "X_normalized=StandardScaler().fit_transform(X)\n",
    "Y_encoded=LabelEncoder().fit_transform(Y)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X_normalized,Y_encoded,test_size=size_of_test_data)\n",
    "c=GaussianNB().fit(X_train,Y_train.ravel())\n",
    "\n",
    "predicted_NB_Y=c.predict(X_test)\n",
    "\n",
    "ac=accuracy_score(Y_test,predicted_NB_Y)\n",
    "f1result=f1_score(Y_test,predicted_NB_Y)\n",
    "precision_result=precision_score(Y_test,predicted_NB_Y)\n",
    "recall_result=recall_score(Y_test,predicted_NB_Y)\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test,predicted_NB_Y).ravel()\n",
    "tpr=tp / (tp + fn)\n",
    "fnr=fn/(tp+fn)\n",
    "fpr=fp / (fp + tn)\n",
    "tnr=tn/(tn+fp)\n",
    "final_result.append([\"NB\",f1result,precision_result,recall_result,tp,tn,fp,fn,fnr])\n",
    "print(\"============= NB finished.===============\")\n",
    "#################################  RF  below  #################################################\n",
    "\n",
    "X=data.drop([\"label\",\"size\",\"Entropy\",\"Name\",\"SectionCharacteristics\"], axis=1)\n",
    "Y=pandas.DataFrame(data[\"label\"])\n",
    "Y=Y.applymap(str)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=size_of_test_data)\n",
    "param_grid = [\n",
    "{'n_estimators': [10,20,30],\n",
    " 'max_features': [5, 10], \n",
    " 'min_samples_split':[2,4,6,8],\n",
    " 'max_depth': [10, 15, 20],\n",
    " 'random_state':[20],\n",
    " 'bootstrap': [True, False]}\n",
    "]\n",
    "\n",
    "grid_search_forest = GridSearchCV(RandomForestClassifier(), param_grid, cv=10, scoring='neg_mean_squared_error')\n",
    "grid_search_forest.fit(X_train, Y_train.values.ravel())\n",
    "rf=RandomForestClassifier()\n",
    "rf=grid_search_forest.best_estimator_\n",
    "grid_rf_predicted = rf.predict(X_test)\n",
    "\n",
    "\n",
    "ac=accuracy_score(Y_test,grid_rf_predicted)\n",
    "f1result=f1_score(Y_test,grid_rf_predicted,pos_label='1')\n",
    "precision_result=precision_score(Y_test,grid_rf_predicted,pos_label='1')\n",
    "recall_result=recall_score(Y_test,grid_rf_predicted,pos_label='1')\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test,grid_rf_predicted).ravel()\n",
    "tpr=tp / (tp + fn)\n",
    "fnr=fn/(tp+fn)\n",
    "fpr=fp / (fp + tn)\n",
    "tnr=tn/(tn+fp)\n",
    "final_result.append([\"RF\",f1result,precision_result,recall_result,tp,tn,fp,fn,fnr])\n",
    "print(\"============= RF finished.===============\")\n",
    "################################  SVM below ##########################################\n",
    "X=None\n",
    "Y=None\n",
    "X_train=None\n",
    "X_test=None\n",
    "Y_train=None\n",
    "Y_test=None\n",
    "\n",
    "X=data.drop([\"label\",\"size\",\"Entropy\",\"Name\",\"SectionCharacteristics\"], axis=1)\n",
    "Y=pandas.DataFrame(data[\"label\"])\n",
    "\n",
    "X_normalized=StandardScaler().fit_transform(X)\n",
    "Y_encoded=LabelEncoder().fit_transform(Y)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X_normalized,Y_encoded,test_size=0.20)\n",
    "param_grid = {'C': [0.1, 1],# 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['linear','poly','rbf','sigmoid']\n",
    "              #'degree': [3,4,5,6]\n",
    "             }  \n",
    "\n",
    "grid = GridSearchCV(svm.SVC(), param_grid, refit = True, verbose = 3) \n",
    "grid.fit(X_train, Y_train)\n",
    "grid_svm_predicted = grid.predict(X_test) \n",
    "#print(\"\\n\\n SVM \\t Confusion matrix:\\n\", confusion_matrix(Y_test, grid_svm_predicted))\n",
    "#measure(\"SVM\", Y_test,grid_svm_predicted)\n",
    "ac=accuracy_score(Y_test,grid_svm_predicted)\n",
    "f1result=f1_score(Y_test,grid_svm_predicted)\n",
    "precision_result=precision_score(Y_test,grid_svm_predicted)\n",
    "recall_result=recall_score(Y_test,grid_svm_predicted)\n",
    "    #tn, fp, fn, tp=confusion_matrix(y,pred).ravel()\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test,grid_svm_predicted).ravel()\n",
    "tpr=tp / (tp + fn)\n",
    "fnr=fn/(tp+fn)\n",
    "fpr=fp / (fp + tn)\n",
    "tnr=tn/(tn+fp)\n",
    "final_result.append([\"SVM\",f1result,precision_result,recall_result,tp,tn,fp,fn,fnr])\n",
    "print(\"============= SVM finished.===============\")\n",
    "\n",
    "###########################  Decision Tree #################################################\n",
    "X=None\n",
    "Y=None\n",
    "X_train=None\n",
    "X_test=None\n",
    "Y_train=None\n",
    "Y_test=None\n",
    "\n",
    "\n",
    "X=data.drop([\"label\",\"size\",\"Entropy\",\"Name\",\"SectionCharacteristics\"], axis=1)\n",
    "Y=pandas.DataFrame(data[\"label\"])\n",
    "\n",
    "X_normalized=StandardScaler().fit_transform(X)\n",
    "Y_encoded=LabelEncoder().fit_transform(Y)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X_normalized,Y_encoded,test_size=0.20)\n",
    "param_grid = [\n",
    "{'max_features': ['auto'], \n",
    " 'min_samples_split':[2,4,6,8,10]}\n",
    "]\n",
    "grid_search_DT = GridSearchCV(tree.DecisionTreeClassifier(), param_grid)\n",
    "model = tree.DecisionTreeClassifier()\n",
    "grid_search_DT.fit(X_train,Y_train)\n",
    "grid_dt_predicted=grid_search_DT.predict(X_test)\n",
    "\n",
    "ac=accuracy_score(Y_test,grid_dt_predicted)\n",
    "f1result=f1_score(Y_test,grid_dt_predicted)\n",
    "precision_result=precision_score(Y_test,grid_dt_predicted)\n",
    "recall_result=recall_score(Y_test,grid_dt_predicted)\n",
    "tn, fp, fn, tp = confusion_matrix(Y_test,grid_dt_predicted).ravel()\n",
    "tpr=tp / (tp + fn)\n",
    "fnr=fn/(tp+fn)\n",
    "fpr=fp / (fp + tn)\n",
    "tnr=tn/(tn+fp)\n",
    "final_result.append([\"DT\",f1result,precision_result,recall_result,tp,tn,fp,fn,fnr])\n",
    "print(\"============= DT finished.===============\")\n",
    "\n",
    "\n",
    "###############################  LightGBM  #####################################################\n",
    "\n",
    "\n",
    "def lgclf(num_iteration,min_data_in_leaf,learn_rate,max_depth,n_estimator,max_bin):\n",
    "    global X_train\n",
    "    global Y_train\n",
    "    global X_test\n",
    "    global Y_test\n",
    "    global best_score\n",
    "    global temp_result\n",
    "    \n",
    "    model=lightgbm.LGBMClassifier(boost='dart',num_iteration=int(num_iteration),min_data_in_leaf=int(min_data_in_leaf),learning_rate=learn_rate,max_depth=int(max_depth),n_estimators=int(n_estimator),max_bin=int(max_bin))\n",
    "    model.fit(X_train,Y_train)\n",
    "    \n",
    "    predicted_LGBM_Y=model.predict(X_test)\n",
    "    \n",
    "    recall_result=recall_score(Y_test,predicted_LGBM_Y)\n",
    "    ac=accuracy_score(Y_test,predicted_LGBM_Y)\n",
    "    f1result=f1_score(Y_test,predicted_LGBM_Y)\n",
    "    precision_result=precision_score(Y_test,predicted_LGBM_Y)\n",
    "    tn, fp, fn, tp = confusion_matrix(Y_test,predicted_LGBM_Y).ravel()\n",
    "    tpr=tp / (tp + fn)\n",
    "    fnr=fn/(tp+fn)\n",
    "    fpr=fp / (fp + tn)\n",
    "    tnr=tn/(tn+fp)\n",
    "    \n",
    "    if recall_result > best_score:\n",
    "        best_score=recall_result\n",
    "        temp_result=[\"LGBM\",f1result,precision_result,recall_result,tp,tn,fp,fn,fnr]\n",
    "        with open(\"LGBM\",\"wb\") as my_classifier:\n",
    "            pickle.dump(model, my_classifier)\n",
    "            my_classifier.close()\n",
    "    return recall_result\n",
    "\n",
    "\n",
    "#==============================================================================\n",
    "\n",
    "X=None\n",
    "Y=None\n",
    "X_train=None\n",
    "X_test=None\n",
    "Y_train=None\n",
    "Y_test=None\n",
    "best_score=0\n",
    "temp_result=[]\n",
    "\n",
    "X=data.drop([\"label\",\"size\",\"Entropy\",\"Name\",\"SectionCharacteristics\"], axis=1)\n",
    "Y=pandas.DataFrame(data[\"label\"])\n",
    "\n",
    "for e in X.columns:\n",
    "    column_type=X[e].dtype\n",
    "    if column_type==\"object\":\n",
    "        X[e]=data[e].astype(\"category\")\n",
    "\n",
    "for l in Y.columns:\n",
    "    column_type=Y[l].dtype\n",
    "    if column_type==\"object\":\n",
    "        Y[l]=Y[l].astype(\"int\")\n",
    "\n",
    "X_train, X_test, Y_train, Y_test=train_test_split(X,Y,test_size=0.20)\n",
    "\n",
    "\n",
    "bop=BayesianOptimization(lgclf, {'num_iteration':(200,1000),\n",
    "                                 'min_data_in_leaf':(30,40),\n",
    "                                 'learn_rate':(0.01,0.05),\n",
    "                                 'max_depth':(30,60),\n",
    "                                 'n_estimator':(40,60),\n",
    "                                 'max_bin':(300,365)})\n",
    "bop.maximize(50,5)\n",
    "\n",
    "#final_result.append([\"LGBM\",f1result,precision_result,recall_result,tp,tn,fp,fn,fnr])\n",
    "###################################################################\n",
    "print(\"============= LGBM finished.===============\")\n",
    "final_result.append(deepcopy(temp_result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
